{"componentChunkName":"component---src-templates-blog-post-js","path":"/hadoop-scala-spark-config/","result":{"data":{"site":{"siteMetadata":{"title":"eternitrance"}},"markdownRemark":{"id":"b91250c1-e0d9-52b9-8452-4fb6fc7539c4","excerpt":"前期准备工作 CentOS 7 JDK 1.8（自行准备，此文不叙） https://hadoop.apache.org/releases.html 下载 Hadoop 3.x 版本 https://www.scala-lang.org/download/ 下载 Scala 2.12.x 版本（.tgz File…","html":"<h2>前期准备工作</h2>\n<ol>\n<li>CentOS 7</li>\n<li>JDK 1.8（自行准备，此文不叙）</li>\n<li><a href=\"https://hadoop.apache.org/releases.html\">https://hadoop.apache.org/releases.html</a> 下载 Hadoop 3.x 版本</li>\n<li><a href=\"https://www.scala-lang.org/download/\">https://www.scala-lang.org/download/</a> 下载 Scala 2.12.x 版本（.tgz File）</li>\n<li>\n<p><a href=\"http://spark.apache.org/downloads.html\">http://spark.apache.org/downloads.html</a> 下载 Spark 2.3.x 版本</p>\n<ul>\n<li>Choose a package type:  Pre-built for Apache Hadoop 2.7 and later</li>\n</ul>\n</li>\n<li>全部下载好后，将压缩包放入 <code class=\"language-text\">/opt/sources</code> 文件夹下，将各个压缩包解压的文件夹放入 <code class=\"language-text\">/opt</code> 文件夹下。</li>\n</ol>\n<h2>全局设置</h2>\n<p><code class=\"language-text\">/etc/profile</code> 文件中添加如下内容：</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token comment\">## Java</span>\n<span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">JAVA_HOME</span><span class=\"token operator\">=</span>/opt/jdk1.8.0_181\n\n<span class=\"token comment\">## Hadoop</span>\n<span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">HADOOP_HOME</span><span class=\"token operator\">=</span>/opt/hadoop-3.1.1\n\n<span class=\"token comment\">## HBase</span>\n<span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">HBASE_HOME</span><span class=\"token operator\">=</span>/opt/hbase-1.4.6\n\n<span class=\"token comment\">## ZooKeeper</span>\n<span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">ZOOKEEPER_HOME</span><span class=\"token operator\">=</span>/opt/zookeeper-3.4.12\n<span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\"><span class=\"token environment constant\">PATH</span></span><span class=\"token operator\">=</span><span class=\"token variable\">$HADOOP_HOME</span>/bin:<span class=\"token variable\">$HADOOP_HOME</span>/sbin:<span class=\"token variable\">$HBASE_HOME</span>/bin:<span class=\"token variable\">$ZOOKEEPER_HOME</span>/bin:<span class=\"token variable\">$JAVA_HOME</span>/bin:<span class=\"token environment constant\">$PATH</span>\n\n<span class=\"token comment\">## Scala</span>\n<span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">SCALA_HOME</span><span class=\"token operator\">=</span>/opt/scala-2.12.6\n<span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\"><span class=\"token environment constant\">PATH</span></span><span class=\"token operator\">=</span><span class=\"token environment constant\">$PATH</span><span class=\"token builtin class-name\">:</span><span class=\"token variable\">$SCALA_HOME</span>/bin\n\n<span class=\"token comment\">## Spark</span>\n<span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">SPARK_HOME</span><span class=\"token operator\">=</span>/opt/spark-2.3.1-bin-hadoop2.7\n<span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\"><span class=\"token environment constant\">PATH</span></span><span class=\"token operator\">=</span><span class=\"token environment constant\">$PATH</span><span class=\"token builtin class-name\">:</span><span class=\"token variable\">$SPARK_HOME</span>/bin</code></pre></div>\n<p>设置完毕后，记得要： <code class=\"language-text\">source /etc/profile</code></p>\n<h2>Hadoop 3.x 伪分布配置</h2>\n<ol>\n<li>\n<p><code class=\"language-text\">/opt/hadoop-3.1.1/etc/hadoop/hadoop-env.sh</code></p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token comment\"># The java implementation to use. By default, this environment</span>\n<span class=\"token comment\"># variable is REQUIRED on ALL platforms except OS X!</span>\n<span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">JAVA_HOME</span><span class=\"token operator\">=</span>/opt/jdk1.8.0_181</code></pre></div>\n</li>\n<li>\n<p><code class=\"language-text\">/opt/hadoop-3.1.1/etc/hadoop/core-site.xml</code></p>\n<div class=\"gatsby-highlight\" data-language=\"xml\"><pre class=\"language-xml\"><code class=\"language-xml\"><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>configuration</span><span class=\"token punctuation\">></span></span>\n   <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>property</span><span class=\"token punctuation\">></span></span>\n       <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>name</span><span class=\"token punctuation\">></span></span>hadoop.tmp.dir<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>name</span><span class=\"token punctuation\">></span></span>\n       <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>value</span><span class=\"token punctuation\">></span></span>/home/users/hadoop/hadoop/tmp<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>value</span><span class=\"token punctuation\">></span></span>\n   <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>property</span><span class=\"token punctuation\">></span></span>\n   <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>property</span><span class=\"token punctuation\">></span></span>\n       <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>name</span><span class=\"token punctuation\">></span></span>fs.default.name<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>name</span><span class=\"token punctuation\">></span></span>\n       <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>value</span><span class=\"token punctuation\">></span></span>hdfs://localhost:9000<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>value</span><span class=\"token punctuation\">></span></span>\n   <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>property</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>configuration</span><span class=\"token punctuation\">></span></span></code></pre></div>\n</li>\n<li>\n<p><code class=\"language-text\">/opt/hadoop-3.1.1/etc/hadoop/hdfs-site.xml</code></p>\n<div class=\"gatsby-highlight\" data-language=\"xml\"><pre class=\"language-xml\"><code class=\"language-xml\"><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>configuration</span><span class=\"token punctuation\">></span></span>\n   <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>property</span><span class=\"token punctuation\">></span></span>\n       <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>name</span><span class=\"token punctuation\">></span></span>dfs.datanode.data.dir<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>name</span><span class=\"token punctuation\">></span></span>\n       <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>value</span><span class=\"token punctuation\">></span></span>/home/users/hadoop/hadoop/data<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>value</span><span class=\"token punctuation\">></span></span>\n   <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>property</span><span class=\"token punctuation\">></span></span>\n   <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>property</span><span class=\"token punctuation\">></span></span>\n       <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>name</span><span class=\"token punctuation\">></span></span>dfs.namenode.name.dir<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>name</span><span class=\"token punctuation\">></span></span>\n       <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>value</span><span class=\"token punctuation\">></span></span>/home/users/hadoop/hadoop/name<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>value</span><span class=\"token punctuation\">></span></span>\n   <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>property</span><span class=\"token punctuation\">></span></span>\n   <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>property</span><span class=\"token punctuation\">></span></span>\n       <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>name</span><span class=\"token punctuation\">></span></span>dfs.http.address<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>name</span><span class=\"token punctuation\">></span></span>\n       <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>value</span><span class=\"token punctuation\">></span></span>0.0.0.0:8100<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>value</span><span class=\"token punctuation\">></span></span>\n   <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>property</span><span class=\"token punctuation\">></span></span>\n   <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>property</span><span class=\"token punctuation\">></span></span>\n       <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>name</span><span class=\"token punctuation\">></span></span>dfs.replication<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>name</span><span class=\"token punctuation\">></span></span>\n       <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>value</span><span class=\"token punctuation\">></span></span>1<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>value</span><span class=\"token punctuation\">></span></span>\n   <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>property</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>configuration</span><span class=\"token punctuation\">></span></span></code></pre></div>\n</li>\n<li>\n<p><code class=\"language-text\">/opt/hadoop-3.1.1/sbin/start-dfs.sh</code> 和 <code class=\"language-text\">/opt/hadoop-3.1.1/sbin/stop-dfs.sh</code></p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token assign-left variable\">HDFS_DATANODE_USER</span><span class=\"token operator\">=</span>root\n<span class=\"token assign-left variable\">HDFS_DATANODE_SECURE_USER</span><span class=\"token operator\">=</span>hdfs\n<span class=\"token assign-left variable\">HDFS_NAMENODE_USER</span><span class=\"token operator\">=</span>root\n<span class=\"token assign-left variable\">HDFS_SECONDARYNAMENODE_USER</span><span class=\"token operator\">=</span>root</code></pre></div>\n</li>\n<li>\n<p>(Optional) <code class=\"language-text\">/opt/hadoop-3.1.1/sbin/start-yarn.sh</code> 和 <code class=\"language-text\">/opt/hadoop-3.1.1/sbin/start-yarn.sh</code></p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token assign-left variable\">YARN_RESOURCEMANAGER_USER</span><span class=\"token operator\">=</span>root\n<span class=\"token assign-left variable\">HDFS_DATANODE_SECURE_USER</span><span class=\"token operator\">=</span>yarn\n<span class=\"token assign-left variable\">YARN_NODEMANAGER_USER</span><span class=\"token operator\">=</span>root</code></pre></div>\n</li>\n<li><code class=\"language-text\">hdfs namenode -format</code></li>\n<li><code class=\"language-text\">start-dfs.sh</code></li>\n</ol>\n<h2>测试 Scala 是否正常</h2>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token punctuation\">[</span>root@localhost ~<span class=\"token punctuation\">]</span><span class=\"token comment\"># scala -version</span>\n\nScala code runner version <span class=\"token number\">2.12</span>.6 -- Copyright <span class=\"token number\">2002</span>-2018, LAMP/EPFL and Lightbend, Inc.</code></pre></div>\n<h2>测试 Spark 是否正常</h2>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token punctuation\">[</span>root@localhost ~<span class=\"token punctuation\">]</span><span class=\"token comment\"># spark-shell</span>\n<span class=\"token number\">2018</span>-09-13 <span class=\"token number\">15</span>:13:57 WARN  Utils:66 - Your hostname, localhost.localdomain resolves to a loopback address: <span class=\"token number\">127.0</span>.0.1<span class=\"token punctuation\">;</span> using <span class=\"token number\">192.168</span>.123.101 instead <span class=\"token punctuation\">(</span>on interface enp0s3<span class=\"token punctuation\">)</span>\n<span class=\"token number\">2018</span>-09-13 <span class=\"token number\">15</span>:13:57 WARN  Utils:66 - Set SPARK_LOCAL_IP <span class=\"token keyword\">if</span> you need to <span class=\"token builtin class-name\">bind</span> to another address\n<span class=\"token number\">2018</span>-09-13 <span class=\"token number\">15</span>:13:57 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library <span class=\"token keyword\">for</span> your platform<span class=\"token punctuation\">..</span>. using builtin-java classes where applicable\nSetting default log level to <span class=\"token string\">\"WARN\"</span><span class=\"token builtin class-name\">.</span>\nTo adjust logging level use sc.setLogLevel<span class=\"token punctuation\">(</span>newLevel<span class=\"token punctuation\">)</span>. For SparkR, use setLogLevel<span class=\"token punctuation\">(</span>newLevel<span class=\"token punctuation\">)</span>.\nSpark context Web UI available at http://192.168.123.101:4040\nSpark context available as <span class=\"token string\">'sc'</span> <span class=\"token punctuation\">(</span>master <span class=\"token operator\">=</span> local<span class=\"token punctuation\">[</span>*<span class=\"token punctuation\">]</span>, app <span class=\"token function\">id</span> <span class=\"token operator\">=</span> local-1536822855033<span class=\"token punctuation\">)</span>.\nSpark session available as <span class=\"token string\">'spark'</span><span class=\"token builtin class-name\">.</span>\nWelcome to\n      ____              __\n     / __/__  ___ _____/ /__\n    _<span class=\"token punctuation\">\\</span> <span class=\"token punctuation\">\\</span>/ _ <span class=\"token punctuation\">\\</span>/ _ `/ __/  '_/\n   /___/ .__/<span class=\"token punctuation\">\\</span>_,_/_/ /_/<span class=\"token punctuation\">\\</span>_<span class=\"token punctuation\">\\</span>   version <span class=\"token number\">2.3</span>.1\n      /_/\n         \nUsing Scala version <span class=\"token number\">2.11</span>.8 <span class=\"token punctuation\">(</span>Java HotSpot<span class=\"token punctuation\">(</span>TM<span class=\"token punctuation\">)</span> <span class=\"token number\">64</span>-Bit Server VM, Java <span class=\"token number\">1.8</span>.0_181<span class=\"token punctuation\">)</span>\nType <span class=\"token keyword\">in</span> expressions to have them evaluated.\nType :help <span class=\"token keyword\">for</span> <span class=\"token function\">more</span> information.\n\nscala<span class=\"token operator\">></span> </code></pre></div>","frontmatter":{"title":"Hadoop, Scala, Spark 简单安装与配置","date":"September 13, 2018","description":"关于之前提到要写 JS 的 this，肯定会更的... 先来一篇水文吧！"}}},"pageContext":{"slug":"/hadoop-scala-spark-config/","previous":{"fields":{"slug":"/a-experience-and-a-frontend-test/"},"frontmatter":{"title":"一次经历 一次笔试"}},"next":{"fields":{"slug":"/javascript-this-intro/"},"frontmatter":{"title":"JavaScript 中的 this 指向"}}}},"staticQueryHashes":["1353881592","2841359383"]}